Summary
NOTES TO LLMs:
Always run python code via uv run or uv python etc.

battle_arena.py:33 builds a deterministic pymunk-powered arena that tracks bots, projectiles, wall geometry, and event timelines for later visualization.
bot_runner_python.py:101 now compiles LLM-provided Python bot functions inside a RestrictedPython sandbox, enforces tight execution timeouts, and sanitizes returned actions (including bounded per-bot memory) before they reach the arena.
llm_bot_controller.py:13 supplies templated aggressive/defensive/sniper behaviors and reproduces in-sim perception (FOV, occlusion) so bots receive consistent visible-object inputs.
battle_runner_cli.py:40 orchestrates the match loop: compiling bot code, stepping physics/control ticks, recording summaries, and wiring battle logs into the viewer front-ends.
viewer_2d_pygame.py:13 and viewer_3d_pygfx.py:1 render those timelines with interactive playback, bot selection, tactical overlays, and optional visibility debugging.
Next Steps

Fix the runner import in battle_runner_cli.py:11 to point at bot_runner_python.py, otherwise the battle harness will fail to start.
Replace the Unix-only signal.alarm timeout in bot_runner_python.py:52 with a cross-platform approach (e.g., worker thread + timer) so Windows users can run matches.
Add a smoke test that runs run_python_battle end-to-end and asserts the generated summary keys, catching regressions in log/summary structure before they reach the viewers.


Critique of control design:
Here’s a focused review of the current Python-function control path and how it lines up with your three questions.

Short Answers

Bot functions have enough for simple reactive control, but not for robust, stateful tactics. Key self-state and history are missing.
LLMs don’t get enough info yet to write better next-gen code; there’s no feedback loop or API contract/prompt data wired in.
The signaling scaffold is promising, but emergent team comms will be weak without a team bus or “last heard” memory beyond line-of-sight.
What Bot Functions Receive

API: bot_function(observation) where observation bundles visible_objects, self (id/team/pose/vel/hp/cooldown/can_fire/tick/time), move_history, world params, allowed_signals, and prior memory. Results still resolve to move|fire|rotate|dodge plus optional signal, and may return a bounded memory dict for the next tick (bot_runner_python.py:333; llm_bot_controller.py:127–305).
Sensors: ray-marched visible_objects with occlusion; includes walls (intersections), enemies/friends (pos, vel, hp, id, team, bearing, distance, signal), projectiles (pos, vel, ttl) (llm_bot_controller.py:127, 199–236, 238–269, 271–289).
State history: move_history carries the last 12 sanitized actions with tick/time context (llm_bot_controller.py:167–207, 314–351).
Frequency: functions run ~5 Hz (every 24 control ticks at 120 Hz) (battle_runner_cli.py:108–121, 141–143).
Actions mapping: set_single_bot_action handles move (to x,y), fire (aim at x,y), rotate (absolute deg), dodge (deg) (battle_arena.py:299–391).
Gaps Impacting Control

Missing self-state: ✅ Addressed 2025-09-17 – observation.self includes id, team, pose, velocity, hp, cooldown_remaining, can_fire, time, tick (llm_bot_controller.py:214–240).
No memory: ✅ Addressed 2025-09-17 – runner now accepts/returns sanitized per-bot memory dicts (bot_runner_python.py:271–313, 356–409).
Empty move_history: ✅ Addressed 2025-09-17 – controller records the last 12 actions with tick/time context (llm_bot_controller.py:167–207, 302–321).
Hidden world params: ✅ Addressed 2025-09-17 – observation.params exposes key arena constants (llm_bot_controller.py:242–259).
Unknown shot gating: ✅ Addressed 2025-09-17 – observation.self includes cooldown_remaining and can_fire sourced from battle_arena.get_fire_status (battle_arena.py:125–153, 402–440).
Rate control: 5 Hz is fine but should be configurable per bot/personality to explore “varying frequency” controllers (battle_runner_cli.py:108–121).
Do LLMs Get Enough To Write Better Code Next Time?

Current flow assigns static templates (llm_bot_controller.py:24–35, 314–510). There is no prompt, no API doc, no telemetry feedback, no validation results fed back.
For code-improving loops, the LLM needs:
A stable, explicit API contract for inputs/outputs with examples and edge cases (bot_runner_python.py:259–278, 333–360; battle_arena.py:299–391).
Per-bot metrics and summaries: hit_rate, damage, kills, deaths, timeouts/errors, execution-time budget usage (battle_arena.py:960–1052 for scoring; runner stats bot_runner_python.py:426–432; battle_runner_cli.py:157–176).
Compact battle traces: e.g., last N decisions, observations, and outcomes; confidence flags for whether actions were no-ops due to gating.
Safety/test harness results: compile/log of exceptions, schema violations, timeouts; unit-style checks the code must satisfy (no recursion, bounded loops, no imports, <X ms avg).
Suggest wiring a “trainer” phase that:
Exports a small training bundle per bot (contract, stats, top mistakes, short episode traces).
Prompts the LLM to emit new code; compiles + runs a brief eval arena; compares deltas.
Accepts code only if it meets latency/safety/score thresholds.
Emergent Signals

Good foundations:
Enumerated, sanitized signals (bot_runner_python.py:50–78; sanitize at 353–360).
Signals are visible from teammates that are visible in FOV (llm_bot_controller.py:219–236).
Limitations:
Line-of-sight only: if teammates aren’t visible (occluded/out of FOV), their signal isn’t available; this weakens team cohesion in spread-out play.
No payload beyond a symbol; that limits expressivity.
Line-of-sight signaling remains an intentional constraint for now; richer team buses are deferred until we have stronger safety tooling for inter-bot comms.
Improvements:
Add a team bus with latency/noise: team_signals listing each teammate’s last signal + age, optionally even if not visible. Or keep “last heard” in a persisted memory channel.
Optional small numeric payload: e.g., signal_data with 1–2 bounded scalars (e.g., urgency, target angle/id) for richer emergent protocols without opening the door to arbitrary data.
Log and expose to LLM how signal usage correlates with outcomes to incentivize its emergent development.
Safety and Robustness Concerns

Timeout containment: threads can’t be killed; a timed-out function keeps running in the background (bot_runner_python.py:96–125). Move execution into a subprocess (per call or per bot) with cgroups/rlimits for real wall-time and memory limits; kill on timeout.
Import surface: __import__ is allowed in builtins (bot_runner_python.py:205–229), so bot code can import os/sys/.... Remove __import__, pre-bind only safe modules (math, maybe a small random) and reject import statements via AST validation.
Top-level effects: exec(source_code, namespace) runs all top-level code before you ever call the function (bot_runner_python.py:231–239). Parse AST and only allow a single function def named bot_function with no top-level code.
Pre-exec checks: add static checks (no while True, no comprehensions with large ranges, no globals, bounded list sizes) and a micro-benchmark to reject slow code prior to battle.
High-Impact, Low-Risk Changes

Add self-state and params to inputs; fill move_history; keep visible_objects as-is for now:
battle_runner_cli.py:114–121 to pass self_state, params, move_history.
llm_bot_controller.py: add real move history tracking and a get_self_state helper.
Add per-bot memory pass-through: let function return {..., 'memory': {...}} and feed back next call (sanitize keys/values).
Make function-call rate configurable via CLI and per-bot personality (battle_runner_cli.py:108–121).
Harden the runner:
Remove __import__; AST-validate only a pure def bot_function(...).
Run bot function in a subprocess with a strict wall-time/memory limit.
Wire LLM training loop:
Export a compact per-bot training bundle after each battle.
Provide a clear API contract doc and minimal examples alongside failure logs.
If you’d like, I can:

Draft the input schema change (self_state/params/memory) and update the runner and controller.
Add a CLI flag for function-call frequency and a per-bot override.
Harden the runner by stripping imports and adding an AST gate.

Perf improvement ideas:
Where Time Goes

Physics loop per bot at 240 Hz and control at 120 Hz applies forces individually (battle_arena.py:1019). With 200+ bodies + many projectiles, this dominates.
Visibility rays per bot every function tick (24 rays × bots × ~5 Hz) with Python math and per-ray wall transforms (llm_bot_controller.py:148-198) is heavy.
Bot execution wrapper spins a thread and deep-copies observation each call (bot_runner_python.py:420-438, 314-347).
Friendly-fire and other O(N) scans (battle_arena.py:520-544) scale poorly at 200 bots.
Logging timeline every 12 ticks (10 Hz) with large JSON payloads adds overhead.
High-Impact Quick Wins

Reduce transform churn for walls
Precompute world-space wall segments once on creation and store arena.wall_segments as tuples; skip get_vertices/local_to_world per ray. Touch: battle_arena.py:620-639, llm_bot_controller.py:158-199.
Segment query for occlusion
Use space.segment_query_first to get nearest wall distance for each ray; only test bots/projectiles closer than that. Touch: llm_bot_controller.py:148-198. Pymunk’s spatial hash is much faster than manual Python loops.
Adaptive sensing
Cache each bot’s last observation keyed by (x,y,theta,tick_of_last_event); recompute only if moved/rotated beyond thresholds or when arena raised a “dirty” flag (shot spawned, bot entered radius). Touch: llm_bot_controller.py:314-321 + add last_obs map; arena raises simple dirty flags on events (battle_arena.py:820-880 hit/shot events already exist).
Skip per-call deep copy + thread in perf mode
In --sim-unsafe, bypass _execute_with_timeout and MappingProxy freeze, calling functions directly with a lightweight observation (bot_runner_python.py:420-438, 323-347). You already added --sim-unsafe; extend it to also skip _make_read_only and avoid scratchpad creation to cut copying.
Lower controller tick at scale
Keep 120 Hz physics, but make function exec frequency adaptive: for ≥100 bots, default to 2–3 Hz; bump to 5–10 Hz when enemies within SENSE_RANGE. Touch: battle_runner_cli.py:108-121, llm_bot_controller.py cache.
Medium Work (1–2 days)

Vectorize visibility math
Move ray-circle and ray-segment tests to a numba-compiled module (still pure Python source). Batch rays per bot to reduce Python call overhead. Touch: new module geom_accel.py, called from llm_bot_controller.py, gating with “numba available”.
Spatial index for entities
Maintain a simple uniform grid or quadtree of bots/projectiles updated each physics tick; only test rays against nearby grid cells. Touch: battle_arena.py to update a grid; llm_bot_controller.py to query cells along each ray.
Batch bot execution
Execute all bots’ functions in a tight loop without per-call thread/queue; keep timeouts disabled only in --sim-unsafe. In safe mode, run timeouts per team in a small threadpool (8–16 threads) to amortize thread overhead.
Larger Investments

Reduce control-loop cost
Vectorize per-bot kinematics (target_vx/vy updates) using NumPy arrays and then assign into pymunk bodies (battle_arena.py:200-240). You still set body.force per bot, but precomputing dx,dy arrays reduces Python math calls.
Pymunk query-driven sensors
Replace ray-marching visibility with Pymunk’s Shape queries (circle queries for bots/projectiles; segment for walls) using filters and collision masks. This leverages C-accelerated broadphase and reduces Python math.
Optional Cython/extension
Port visibility and friendly-fire checks into a compiled extension for constant speedups at high N.
Friendly-Fire and Firing

Pre-filter teammate cones using spatial index
Limit _check_friendly_fire_risk to teammates within a 1–2m lateral band and in front of the bot, not all bots (battle_arena.py:520-544).
Batch fire decision timing
Track a “next_fire_time” and early-out before cone checks when on cooldown (battle_arena.py:402-440), saving work on many calls.
Logging/IO

Decimate timeline for large battles
For N >= 150 bots, log at 5 Hz instead of 10 Hz, with a CLI flag to override. Touch: battle_runner_cli.py:140-143.
Optional compressed output
Offer --compress-output to gzip JSON; cheaper disk/IO at the end.
Validation Plan

Add a simple perf benchmark script: N bots per side (20/50/100), duration 10s, record wall clock and CPU time for modes: baseline, precomputed walls, segment-query occlusion, unsafe no-thread, adaptive sensing.
Ensure functional parity: compare summary keys (winner, durations, event counts within tolerance), visible object counts distribution and bot actions frequency.
Suggested Implementation Order

Precompute wall segments; skip per-ray transforms.
Segment-query occlusion + adaptive sensing cache.
In --sim-unsafe, bypass deep-copy/MappingProxy and thread timeouts; direct function calls.
Optional: reduce function tick rate automatically for large N.
Profile; if needed, add numba-accelerated geometry and grid index.
If you want, I can start with (1) and (3) now since they’re surgical, then wire (2) next.


